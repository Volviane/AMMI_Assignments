{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import dlc_practical_prologue as prologue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The objective of this session is to implement a convolutional network and test the influence of the architecture on the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target, test_input, test_target = \\\n",
    "    prologue.load_data(one_hot_labels = True, normalize = True, flatten = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(256, 200)\n",
    "        self.fc2 = nn.Linear(200, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3, stride=3))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9033293426036835\n",
      "1 0.7755392417311668\n",
      "2 0.6989829018712044\n",
      "3 0.6369436867535114\n",
      "4 0.5857527442276478\n",
      "5 0.5477792881429195\n",
      "6 0.5352986119687557\n",
      "7 0.4928424321115017\n",
      "8 0.46781037747859955\n",
      "9 0.45788421109318733\n",
      "10 0.41965536773204803\n",
      "11 0.4122872091829777\n",
      "12 0.3947731666266918\n",
      "13 0.3983162231743336\n",
      "14 0.369354709982872\n",
      "15 0.34924130886793137\n",
      "16 0.3518020734190941\n",
      "17 0.33309604972600937\n",
      "18 0.3338467739522457\n",
      "19 0.32091527432203293\n",
      "20 0.3038053549826145\n",
      "21 0.3046022206544876\n",
      "22 0.284149082377553\n",
      "23 0.2884716186672449\n",
      "24 0.27921703085303307\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target = Variable(train_input), Variable(train_target)\n",
    "\n",
    "model, criterion = Net(), nn.MSELoss()\n",
    "eta, mini_batch_size = 1e-1, 100\n",
    "\n",
    "for e in range(0, 25):\n",
    "    sum_loss = 0\n",
    "    # We do this with mini-batches\n",
    "    for b in range(0, train_input.size(0), mini_batch_size):\n",
    "        output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "        loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "        sum_loss = sum_loss + loss.item()\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        for p in model.parameters():\n",
    "            p.data.sub_(eta * p.grad.data)\n",
    "    print(e, sum_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,train_input, train_target, mini_batch_size):\n",
    "    \n",
    "    train_input, train_target = Variable(train_input), Variable(train_target)\n",
    "    criterion =nn.MSELoss()\n",
    "    eta= 1e-1\n",
    "    \n",
    "    for epoch in range(0, 25):\n",
    "        sum_loss = 0\n",
    "        # We do this with mini-batches\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            sum_loss = sum_loss + loss.item()\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            for p in model.parameters():\n",
    "                p.data.sub_(eta * p.grad.data)\n",
    "    #print(epoch, sum_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mini_batch_size =100\n",
    "train_model(model,train_input, train_target, mini_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors(model, input_,target,mini_batch_size):\n",
    "    model.eval()\n",
    "    output = model(input_)\n",
    "    correct_pred = torch.sum(torch.argmax(output,dim=1)==torch.argmax(target,dim=1)).item()/target.size(0)\n",
    "    return (1 - float(correct_pred) )*100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.799999999999995"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_nb_errors(model=model, \n",
    "                  input_=train_input,\n",
    "                  target=train_target,\n",
    "                  mini_batch_size=mini_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error [6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8, 6.8]\n",
      "test error [13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0]\n"
     ]
    }
   ],
   "source": [
    "train_error = []\n",
    "test_error = []\n",
    "for i in range(10):\n",
    "    train_model(model2,train_input, train_target, mini_batch_size)\n",
    "    loss_train = compute_nb_errors(model=model, \n",
    "                  input_=train_input,\n",
    "                  target=train_target,\n",
    "                  mini_batch_size=mini_batch_size)\n",
    "    loss_test = compute_nb_errors(model=model, \n",
    "                  input_=test_input,\n",
    "                  target=test_target,\n",
    "                  mini_batch_size=mini_batch_size)\n",
    "    \n",
    "    train_error.append(round(loss_train,2))\n",
    "    test_error.append(round(loss_test,2))\n",
    "print('train error',train_error)\n",
    "print('test error', test_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence of the number of hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self,hidden_unit_size):\n",
    "        \n",
    "        super(Net2, self).__init__()\n",
    "        self.hidden_unit_size=hidden_unit_size\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(256, self.hidden_unit_size)\n",
    "        self.fc2 = nn.Linear(self.hidden_unit_size, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3, stride=3))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 hidden unit test error 43.99999999999999 \n",
      "50 hidden unit test error 14.600000000000001 \n",
      "200 hidden unit test error 14.500000000000002 \n",
      "500 hidden unit test error 14.500000000000002 \n",
      "1000 hidden unit test error 13.600000000000001 \n"
     ]
    }
   ],
   "source": [
    "hidden_unit_size =[10,50,200,500,1000]\n",
    "\n",
    "for h in hidden_unit_size:\n",
    "    \n",
    "    model3 = Net2(h)\n",
    "    \n",
    "    train_model(model3,train_input, train_target, mini_batch_size)\n",
    "    \n",
    "    loss = compute_nb_errors(model=model3, \n",
    "                  input_=test_input,\n",
    "                  target=test_target,\n",
    "                  mini_batch_size=mini_batch_size)\n",
    "    \n",
    "    print('{} hidden unit test error {} '.format(h,loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net3(nn.Module):\n",
    "    def __init__(self, hidden_unit):\n",
    "        \n",
    "        super(Net3, self).__init__()\n",
    "        self.hidden_unit = hidden_unit\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(3*3*64, self.hidden_unit)\n",
    "        self.fc2 = nn.Linear(self.hidden_unit, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2,stride=2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2,stride=2))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.fc1(x.view(-1, 3*3*64)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape(h,p=0,k=5,s=1):\n",
    "    return ((h+(2*p)-k)/s)+1\n",
    "\n",
    "def maxp(w1,f,s):\n",
    "    return (w1-f)/s +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_shape(5,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_unit=200\n",
    "model4= Net3(hidden_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.9\n"
     ]
    }
   ],
   "source": [
    "train_model(model4,train_input, train_target, mini_batch_size)\n",
    "    \n",
    "loss = compute_nb_errors(model=model4, \n",
    "                  input_=test_input,\n",
    "                  target=test_target,\n",
    "                  mini_batch_size=mini_batch_size)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
